{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template Matching\n",
    "\n",
    "- Used if we have the smaller image we are looking for exactly cut out of the larger image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Full Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image = cv.imread(\"../data/Files/DATA/sammy.jpg\")\n",
    "\n",
    "'''OpenCV reads images in the BGR color space, but Matplotlib expects images in the RGB (Red, Green, Blue) color space. To address this, the cvtColor function from OpenCV is used to convert the image from BGR to RGB\n",
    "\n",
    "# order of data representation is the only difference between RGB and BGR\n",
    "RGB: Red, Green, Blue (used by most image processing libraries and applications).\n",
    "BGR: Blue, Green, Red (used by OpenCV).'''\n",
    "full_image = cv.cvtColor(full_image,cv.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(full_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Face Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_image = cv.imread(\"../data/Files/DATA/sammy_face.jpg\")\n",
    "face_image = cv.cvtColor(face_image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(face_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can have different methods to look implement TemplateMatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the 6 methods for comparison in a list\n",
    "# Note how we are using strings, later on we'll use the eval()\n",
    "# function to convert to function\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR', 'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "height,width,channel = face_image.shape \n",
    "\n",
    "\n",
    "for current_method in methods:\n",
    "\n",
    "  full_image_copy = full_image.copy()\n",
    "  method = eval(current_method)\n",
    "\n",
    "  # result stores the amount of matching it got in each cell \n",
    "  # if the image was represented as a matrix\n",
    "  result = cv.matchTemplate(full_image_copy,face_image,method)\n",
    "\n",
    "  # minMaxLoc returns where it found the maximum and minimum \n",
    "  # matches along with their location\n",
    "  min_val,max_val,min_loc,max_loc = cv.minMaxLoc(result)\n",
    "  top_left = None\n",
    "\n",
    "  '''cv.TM_SQDIFF_NORMED and cv.TM_SQDIFF calculate the \n",
    "  squared difference between the template and the image \n",
    "  region, with lower values indicating a better match.'''\n",
    "\n",
    "  if current_method in ['cv.TM_SQDIFF_NORMED','cv.TM_SQDIFF']:\n",
    "    top_left = min_loc\n",
    "  else:\n",
    "    top_left = max_loc\n",
    "\n",
    "\n",
    "  top_leftX,top_leftY = top_left\n",
    "\n",
    "  bottom_rightX = top_leftX + width\n",
    "  bottom_rightY = top_leftY + height\n",
    "  \n",
    "  bottom_right = (bottom_rightX,bottom_rightY)\n",
    "\n",
    "  cv.rectangle(img=full_image_copy,pt1=top_left,pt2=bottom_right,color=(0,255,0),thickness=5)\n",
    "\n",
    "  # the plt.subplot function from the Matplotlib library\n",
    "  # to create multiple subplots within a single figure\n",
    "\n",
    "  '''\n",
    "### Understanding the Arguments\n",
    "\n",
    "The arguments passed to [`plt.subplot`] are integers that define the grid layout and the position of the subplot within that grid. The format of the argument is `nrowsncolsindex`, where:\n",
    "\n",
    "- **`nrows`**: The number of rows in the grid.\n",
    "- **`ncols`**: The number of columns in the grid.\n",
    "- **`index`**: The position of the subplot within the grid, starting from 1 in the upper left corner and increasing to the right.'''\n",
    "\n",
    "  plt.subplot(121)\n",
    "  plt.imshow(result)\n",
    "  plt.title(\"HEATMAP of Template Matching\")\n",
    "\n",
    "\n",
    "  plt.subplot(122)\n",
    "  plt.imshow(full_image_copy)\n",
    "  plt.title(\"Template Detection\")\n",
    "\n",
    "  plt.suptitle(current_method)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  print('\\n\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Now let's cutout a specific part of an existing image and look for it in the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get size of the original image \n",
    "height, width, channel = full_image.shape\n",
    "\n",
    "\n",
    "# let's try to cutout the legs \n",
    "# define the region of interest (ROI) coordinates\n",
    "x1, y1, x2, y2 = 450, 1000, 850, 1367  # Corrected coordinates\n",
    "\n",
    "# crop the image using array slicing\n",
    "leg_image = full_image[y1:y2, x1:x2]\n",
    "\n",
    "cv.imwrite('../data/Files/DATA/sammy_leg.jpg',leg_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Leg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Leg Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_image = cv.imread(\"../data/Files/DATA/sammy_leg.jpg\")\n",
    "leg_image = cv.cvtColor(leg_image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(leg_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the 6 methods for comparison in a list\n",
    "# Note how we are using strings, later on we'll use the eval()\n",
    "# function to convert to function\n",
    "\n",
    "\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "           'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "height, width, channel = leg_image.shape\n",
    "\n",
    "\n",
    "for current_method in methods:\n",
    "\n",
    "  full_image_copy = full_image.copy()\n",
    "  method = eval(current_method)\n",
    "\n",
    "  # result stores the amount of matching it got in each cell\n",
    "  # if the image was represented as a matrix\n",
    "  result = cv.matchTemplate(full_image_copy, leg_image, method)\n",
    "\n",
    "  # minMaxLoc returns where it found the maximum and minimum\n",
    "  # matches along with their location\n",
    "  min_val, max_val, min_loc, max_loc = cv.minMaxLoc(result)\n",
    "  top_left = None\n",
    "\n",
    "  '''cv.TM_SQDIFF_NORMED and cv.TM_SQDIFF calculate the \n",
    "  squared difference between the template and the image \n",
    "  region, with lower values indicating a better match.'''\n",
    "\n",
    "  if current_method in ['cv.TM_SQDIFF_NORMED', 'cv.TM_SQDIFF']:\n",
    "    top_left = min_loc\n",
    "  else:\n",
    "    top_left = max_loc\n",
    "\n",
    "  top_leftX, top_leftY = top_left\n",
    "\n",
    "  bottom_rightX = top_leftX + width\n",
    "  bottom_rightY = top_leftY + height\n",
    "\n",
    "  bottom_right = (bottom_rightX, bottom_rightY)\n",
    "\n",
    "  cv.rectangle(img=full_image_copy, pt1=top_left,\n",
    "               pt2=bottom_right, color=(0, 255, 0), thickness=5)\n",
    "\n",
    "  # the plt.subplot function from the Matplotlib library\n",
    "  # to create multiple subplots within a single figure\n",
    "\n",
    "  '''\n",
    "### Understanding the Arguments\n",
    "\n",
    "The arguments passed to [`plt.subplot`] are integers that define the grid layout and the position of the subplot within that grid. The format of the argument is `nrowsncolsindex`, where:\n",
    "\n",
    "- **`nrows`**: The number of rows in the grid.\n",
    "- **`ncols`**: The number of columns in the grid.\n",
    "- **`index`**: The position of the subplot within the grid, starting from 1 in the upper left corner and increasing to the right.'''\n",
    "\n",
    "  plt.subplot(121)\n",
    "  plt.imshow(result)\n",
    "  plt.title(\"HEATMAP of Template Matching\")\n",
    "\n",
    "  plt.subplot(122)\n",
    "  plt.imshow(full_image_copy)\n",
    "  plt.title(\"Template Detection\")\n",
    "\n",
    "  plt.suptitle(current_method)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
